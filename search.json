[{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing","title":"Contributing","text":"contributing guide derived {tidyverse} boilerplate (see high-level contributing guide). questions contributing, please don’t hesitate reach . appreciate every contribution. suggest first reading Getting started tidytags vignette.","code":""},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"contributor-code-of-conduct","dir":"","previous_headings":"","what":"Contributor Code of Conduct","title":"Contributing","text":"Please note package released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"non-technical-contributions-to-tidytags","dir":"","previous_headings":"","what":"Non-technical contributions to {tidytags}","title":"Contributing","text":"Feel free report issues: Questions seeking clarification information. question askers question answerers welcome contributors! Bug reports unplanned malfunctions. found bug, follow issue template create minimal reprex. Enhancement requests ideas new features.","code":""},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"technical-contributions-to-tidytags","dir":"","previous_headings":"","what":"Technical contributions to {tidytags}","title":"Contributing","text":"like contribute {tidytags} code base, follow process : Prerequisites Fork, clone, branch Check Style Document Test Re-check Commit Push pull Check docs Review, revise, repeat Resources Code conduct explains propose change {tidytags} via pull request using Git GitHub. general info contributing {tidytags}, see Resources end document.","code":""},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"prerequisites","dir":"","previous_headings":"Technical contributions to {tidytags}","what":"Prerequisites","title":"Contributing","text":"test {tidytags} package, can use openly shared TAGS tracker collecting tweets associated AECT 2019 since September 30, 2019. TAGS tracker used Using tidytags conference hashtag vignette. Note TAGS tracker read-web browser, utility {tidytags} reading TAGS tracker archive R using read_tags(\"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\") conducting analyses R environment. pull request, always file issue make sure someone {tidytags} team agrees ’s problem, happy basic proposal fixing . don’t want spend bunch time something don’t think real problem appropriate solution. Also make sure read {tidyverse} style guide make sure new code documentation matches existing style. makes review process much smoother.","code":""},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"pr-process","dir":"","previous_headings":"Technical contributions to {tidytags}","what":"PR process","title":"Contributing","text":"welcome contribute pull request (PR) {tidytags}. important thing know tidyverse packages use {roxygen2}: means documentation found R code close source function.","code":""},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"fork-clone-branch","dir":"","previous_headings":"Technical contributions to {tidytags} > PR process","what":"Fork, clone, branch","title":"Contributing","text":"first thing ’ll need fork {tidytags} GitHub repo, clone locally. recommend create branch PR.","code":""},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"check","dir":"","previous_headings":"Technical contributions to {tidytags} > PR process","what":"Check","title":"Contributing","text":"changing anything, make sure package still passes listed flavors R CMD check locally .","code":"goodpractice::goodpractice(quiet = FALSE, ) devtools::check()"},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"style","dir":"","previous_headings":"Technical contributions to {tidytags} > PR process","what":"Style","title":"Contributing","text":"Match existing code style. means follow tidyverse style guide. Use {styler} package apply style guide automatically {spelling} package check spelling. careful make style changes code contributing. find lot code doesn’t meet style guide, better file issue separate PR fix first.","code":"styler::style_pkg() spelling::spell_check_package() spelling::update_wordlist()"},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"document","dir":"","previous_headings":"Technical contributions to {tidytags} > PR process","what":"Document","title":"Contributing","text":"use {roxygen2}, specifically Markdown syntax, create NAMESPACE .Rd files. edits documentation done roxygen comments associated function object. , run devtools::document() rebuild NAMESPACE .Rd files. See RoxygenNote DESCRIPTION version {roxygen2} used.","code":""},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"test","dir":"","previous_headings":"Technical contributions to {tidytags} > PR process","what":"Test","title":"Contributing","text":"use {testthat} testing. Contributions test cases easier review verify. Note {tidytags} queries OpenCage Twitter APIs, testing can bit tricky. sure follow Getting started tidytags vignette establishing OpenCage API key Twitter API tokens conduct local testing. CI testing, view setup-tidytags.R file package testing documentation see fake OAuth tokens set . HTTP testing R book invaluable resource.","code":"devtools::test() devtools::test_coverage()"},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"re-check","dir":"","previous_headings":"Technical contributions to {tidytags} > PR process","what":"Re-check","title":"Contributing","text":"submitting changes, make sure package either still passes R CMD check, warnings /notes changed result edits.","code":"devtools::check() goodpractice::goodpractice(quiet = FALSE)"},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"commit","dir":"","previous_headings":"Technical contributions to {tidytags} > PR process","what":"Commit","title":"Contributing","text":"’ve made changes, write clear commit message describing ’ve done. ’ve fixed closed issue, make sure include keywords (e.g. fixes #17) end commit message (title) automatically close issue PR merged.","code":""},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"push-and-pull","dir":"","previous_headings":"Technical contributions to {tidytags} > PR process","what":"Push and pull","title":"Contributing","text":"’ve pushed commit(s) branch fork, ’re ready make pull request. Pull requests descriptive titles remind reviewers/maintainers PR . can easily view exact changes proposing using either Git diff view RStudio, branch comparison view ’ll taken go create new PR. PR related issue, provide issue number slug description using auto-linking syntax (e.g. #17).","code":""},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"check-the-docs","dir":"","previous_headings":"Technical contributions to {tidytags} > PR process","what":"Check the docs","title":"Contributing","text":"Double check output GitHub Actions CI breakages error messages.","code":""},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"review-revise-repeat","dir":"","previous_headings":"Technical contributions to {tidytags} > PR process","what":"Review, revise, repeat","title":"Contributing","text":"latency period submitting PR review may vary. maintainer review contribution, sure use conventions described revision commits.","code":""},{"path":"https://docs.ropensci.org/tidytags/CONTRIBUTING.html","id":"resources","dir":"","previous_headings":"Technical contributions to {tidytags}","what":"Resources","title":"Contributing","text":"Happy Git GitHub useR Jenny Bryan. Contribute tidyverse covers several ways contribute don’t involve writing code. Contributing Code Tidyverse Jim Hester. Git GitHub Automated checking Object documentation Testing dplyr’s NEWS.md good source examples content styling. Closing issues using keywords GitHub. Autolinked references URLs GitHub. GitHub Guides: Forking Projects.","code":""},{"path":"https://docs.ropensci.org/tidytags/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021, K. Bret Staudt Willet & Joshua M. Rosenberg Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://docs.ropensci.org/tidytags/articles/setup.html","id":"considerations-related-to-ethics-data-privacy-and-human-subjects-research","dir":"Articles","previous_headings":"","what":"Considerations Related to Ethics, Data Privacy, and Human Subjects Research","title":"Getting started with tidytags","text":"reading steps setting {tidytags}, please take moments reflect ethical considerations related social media research. {tidytags} used strict accordance Twitter’s developer terms. Although Institutional Review Boards (IRBs) consider Twitter data {tidytags} analyzes necessarily human subjects research, remain ethical considerations pertaining use {tidytags} package discussed. Even {tidytags} use research purposes (IRB determines study human subjects research), “release personally identifiable sensitive data potentially harmful,” noted rOpenSci Packages guide. Therefore, although can collect Twitter data (can use {tidytags} analyze ), urge care thoughtfulness regarding analyze data communicate results. short, please remember () data collect may people—people may like idea data analyzed included research. recommend Association Internet Researchers’ (AoIR) resources related conducting analyses ethical ways working data people. AoIR’s ethical guidelines may especially helpful navigating tensions related collecting, analyzing, sharing social media data. things mind, let’s get started working common pain points.","code":""},{"path":"https://docs.ropensci.org/tidytags/articles/setup.html","id":"key-task-1--making-sure-your-tags-tracker-can-be-accessed","dir":"Articles","previous_headings":"","what":"Key Task #1. Making sure your TAGS tracker can be accessed","title":"Getting started with tidytags","text":"core functionality {tidytags} retrieve tweets data Twitter Archiving Google Sheet; TAGS). TAGS tracker continuously collects tweets Twitter, based predefined search criteria collection frequency. offer brief overview set TAGS, sure read information TAGS landing page thorough instructions getting started TAGS. recommend using TAGS v6.1.  prompted Make copy TAGS reside Google Drive space. Click button .  TAGS tracker now ready use! Just follow two-steps instructions TAGS tracker:  {tidytags} set access TAGS tracker using {googlesheets4} package. One requirement using {googlesheets4} TAGS tracker “published web.” , TAGS page open web browser, go File >> Publish web.  Link field ‘Entire document’ Embed field ‘Web page.’ everything looks right, click Publish button.  Next, click Share button top right corner Google Sheets window, select Get shareable link, set permissions ‘Anyone link can view.’   input needed tidytags::read_tags() function either entire URL top web browser opened TAGS tracker, Google Sheet identifier (.e., alphanumeric string following “https://docs.google.com/spreadsheets/d/” TAGS tracker’s URL).   sure put quotations marks around URL sheet identifier entering read_tags() function. verify step worked , run following code: read_tags(\"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\") return following:  , try run read_tags() URL sheet identifier. work, carefully review steps .","code":""},{"path":"https://docs.ropensci.org/tidytags/articles/setup.html","id":"key-task-2--getting-and-storing-a-google-api-key","dir":"Articles","previous_headings":"","what":"Key Task #2. Getting and storing a Google API key","title":"Getting started with tidytags","text":"use read_tags(), need Google API key Google Sheets. Follow {gargle} package vignette “get API credentials” (vignette(\"get-api-credentials\", package = \"gargle\")) thorough guide process. general steps follows: Enable Google Sheets API Google Developers Console. , link, click CREATE CREDENTIALS button (see image ).  next screen, select Google Sheets API check “Application data” radio button first prompt, “, ’m using ” button second, following:  Next, ’ll next see screen like one . , name key clearly identifiable title, “API key tidytags.” Leave “Application restrictions” setting None, “API restrictions” select Restrict key check box next Google Sheets API. API needed {tidytags} ensure new Google API key can used access Google Sheets.  Finally, bring Google API key R. Specifically, add key .Renviron file. Edit file directly using usethis::edit_r_environ(scope='user') function. format .Renviron file follows (inputting unique Google API key = sign, quotation marks): GOOGLE_API_KEY = YourGoogleAPIKey Restart R (closing re-opening R/RStudio) key available next R Session. can read Google Sheets API , get help API . Run following line code: Sys.getenv(\"GOOGLE_API_KEY\") API key printed console. , carefully review steps, sure *close re-open R/RStudio).","code":""},{"path":"https://docs.ropensci.org/tidytags/articles/setup.html","id":"key-task-3--getting-and-storing-twitter-api-token","dir":"Articles","previous_headings":"","what":"Key Task #3. Getting and storing Twitter API token","title":"Getting started with tidytags","text":"TAGS tracker archive imported R, {tidytags} allows gather quite bit information related TAGS-collected tweets pull_tweet_data() function. function builds {rtweet} package (via rtweet::lookup_tweets()) query Twitter API. However, access Twitter API, whether {rtweet} {tidytags}, need apply developers’ access Twitter. Twitter’s developer website.","code":""},{"path":"https://docs.ropensci.org/tidytags/articles/setup.html","id":"getting-access-token","dir":"Articles","previous_headings":"Key Task #3. Getting and storing Twitter API token","what":"Getting access token","title":"Getting started with tidytags","text":"Fortunately, {rtweet} documentation already contains thorough vignette, “Obtaining using access tokens” (vignette(\"auth\", package = \"rtweet\")), guide process obtaining Twitter API token. recommend second suggested method listed {rtweet} vignette, 2. Access token/secret method. Following directions, run rtweet::create_token() function save Twitter token. saves Twitter API key token .Renviron file directly using usethis::edit_r_environ(scope='user') function. format .Renviron file follows (inputting unique credentials = sign, quotation marks): Note two separate secrets: TWITTER_API_SECRET (used authenticate application level, relevant using {tidytags}) TWITTER_ACCESS_TOKEN_SECRET(used authenticate end-user level, can allow access one’s private user data). ’ve added Twitter API pieces .Renviron, run rtweet::create_token() following parameters: compiles together pieces Twitter API credentials one token (.rds file) stored securely local machine. {tidytags} functions now retrieve token background, needed. ever set (start working different computer need change Twitter API token). make sure Twitter API token works, restart R session run code rtweet::get_token().","code":"TWITTER_APP = NameOfYourTwitterApp TWITTER_API_KEY = YourConsumerKey TWITTER_API_SECRET = YourConsumerSecretKey TWITTER_ACCESS_TOKEN = YourAccessToken TWITTER_ACCESS_TOKEN_SECRET = YourAccessTokenSecret token <- rtweet::create_token(     app = Sys.getenv('TWITTER_APP'),     consumer_key = Sys.getenv('TWITTER_API_KEY'),     consumer_secret = Sys.getenv('TWITTER_API_SECRET'),     access_token = Sys.getenv('TWITTER_ACCESS_TOKEN'),     access_secret = Sys.getenv('TWITTER_ACCESS_TOKEN_SECRET'))"},{"path":"https://docs.ropensci.org/tidytags/articles/setup.html","id":"key-task-4--getting-and-storing-a-opencage-geocoding-api-key","dir":"Articles","previous_headings":"","what":"Key Task #4. Getting and storing a OpenCage Geocoding API key","title":"Getting started with tidytags","text":"{tidytags} function geocode_tags() pulls OpenCage Geocoding API, requires OpenCage Geocoding API key. Note key task required geocoding functionality provided {tidytags}. OpenCage API allows 2,500 searches per day part free trial. greatly exceed limit, ask upgrade paid plan.","code":""},{"path":"https://docs.ropensci.org/tidytags/articles/setup.html","id":"getting-the-access-key","dir":"Articles","previous_headings":"Key Task #4. Getting and storing a OpenCage Geocoding API key","what":"Getting the access key","title":"Getting started with tidytags","text":"Getting OpenCage Geocoding API key straightforward immediate Twitter API token process. can secure API access key OpenCage directly; Quick Start guide offers helpful guidance (read ). key, OpenCage Geocoding API Documentation offers many additional helps. recommend saving OpenCage Geocoding API key .Renviron file OPENCAGE_KEY (similar Twitter tokens). can quickly access file using R code: , add line file reads (inputting unique OpenCage Key = sign, quotation marks): OPENCAGE_KEY = PasteYourOpenCageKeyHere ’ve saved .Renviron file, quit R session restart. function geocode_tags() work now . Note {tidytags} geocode_tags() function retrieves saved API key automatically securely, won’t need think initial setup. make sure OpenCage Geocoding API key works, restart R session run following code: ’re now ready proceed using {tidytags}! Now good time learn full functionality package walking “Using tidytags conference hashtag” guide (vignette(\"tidytags--conf-hashtags\", package = \"tidytags\")).","code":"if (requireNamespace(\"usethis\", quietly = TRUE) {   usethis::edit_r_environ(scope='user') } Sys.getenv('OPENCAGE_KEY')"},{"path":"https://docs.ropensci.org/tidytags/articles/setup.html","id":"getting-help","dir":"Articles","previous_headings":"","what":"Getting help","title":"Getting started with tidytags","text":"{tidytags} still work progress, fully expect still bugs work functions document better. find issue, question, think something really wish {tidytags} , don’t hesitate email Bret reach Twitter: @bretsw @jrosenberg6432. can also submit issue Github. may also wish try general troubleshooting strategies: Identify causing problem “Unplug plug back ” - restart R, close reopen R RStudio Community - https://community.rstudio.com/ (highly recommended!) Twitter hashtag: #rstats General strategies learning : https://datascienceineducation.com/c17.html","code":""},{"path":"https://docs.ropensci.org/tidytags/articles/tidytags-with-conf-hashtags.html","id":"considerations-related-to-ethics-data-privacy-and-human-subjects-research","dir":"Articles","previous_headings":"","what":"Considerations Related to Ethics, Data Privacy, and Human Subjects Research","title":"Using tidytags with a conference hashtag","text":"working demonstration capabilities {tidytags}, please take moments reflect ethical considerations related social media research. {tidytags} used strict accordance Twitter’s developer terms. Although Institutional Review Boards (IRBs) consider Twitter data {tidytags} analyzes necessarily human subjects research, remain ethical considerations pertaining use {tidytags} package discussed. Even {tidytags} use research purposes (IRB determines study human subjects research), “release personally identifiable sensitive data potentially harmful,” noted rOpenSci Packages guide. Therefore, although can collect Twitter data (can use {tidytags} analyze ), urge care thoughtfulness regarding analyze data communicate results. short, please remember () data collect may people—people may like idea data analyzed included research. recommend Association Internet Researchers’ (AoIR) resources related conducting analyses ethical ways working data people. AoIR’s ethical guidelines may especially helpful navigating tensions related collecting, analyzing, sharing social media data.","code":""},{"path":"https://docs.ropensci.org/tidytags/articles/tidytags-with-conf-hashtags.html","id":"twitter-archiving-google-sheets","dir":"Articles","previous_headings":"","what":"Twitter Archiving Google Sheets","title":"Using tidytags with a conference hashtag","text":"core functionality {tidytags} collecting tweets continuously Twitter Archiving Google Sheet (TAGS). help setting TAGS tracker, see “Getting started tidytags” (vignette(\"setup\", package = \"tidytags\")) vignette, Key Task #1. Additionally, order input data TAGS tracker R, need Google API key Google Sheets. quickly get started obtaining using Google API key, see “Getting started tidytags” (vignette(\"setup\", package = \"tidytags\")) vignette, Key Task #2. , follow {gargle} package vignette “get API credentials” (vignette(\"get-api-credentials\", package = \"gargle\")) thorough guide process.","code":""},{"path":"https://docs.ropensci.org/tidytags/articles/tidytags-with-conf-hashtags.html","id":"read_tags","dir":"Articles","previous_headings":"","what":"read_tags()","title":"Using tidytags with a conference hashtag","text":"simply view TAGS archive, can use read_tags(). , ’ve openly shared TAGS tracker collecting tweets associated AECT 2019 since September 30, 2019. Notice TAGS tracker collecting tweets containing three different hashtags: #aect19, #aect2019, #aect19inspired. September 30, 2020, tracker collected 2,564 tweets. tracker active today. {tidytags} allows work tweets collected TAGS tracker R. done {googlesheets4} package. One requirement using {googlesheets4} TAGS tracker “published web.” , TAGS page open web browser, go File >> Publish web. Link field ‘Entire document’ Embed field ‘Web page.’ everything looks right, click Publish button. Next, click Share button top right corner Google Sheets window, select Get shareable link, set permissions ‘Anyone link can view.’ input needed tidytags::read_tags() function either entire URL top web browser opened TAGS tracker, Google Sheet identifier (.e., alphanumeric string following “https://docs.google.com/spreadsheets/d/” TAGS tracker’s URL). sure put quotations marks around URL sheet identifier entering read_tags() function. , ’re trouble setting publishing TAGS tracker, obtaining Google API key, see “Getting started tidytags” vignette (vignette(\"setup\", package = \"tidytags\")), Key Task #1 Key Task #2. Note alternative ways access TAGS files. One way simply download CSV file Google Sheets. Google Sheets, navigate File -> Download -> Comma-separated values (CSV) . sure TAGS Archive page. file downloaded, can read like like CSV using R.","code":"tags_url <- \"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\" example_df_all <- read_tags(tags_url) dim(example_df_all) #> [1] 2564   18 example_df_all <- readr::read_csv(\"my-downloaded-tags-file.csv\")"},{"path":"https://docs.ropensci.org/tidytags/articles/tidytags-with-conf-hashtags.html","id":"pull_tweet_data","dir":"Articles","previous_headings":"","what":"pull_tweet_data()","title":"Using tidytags with a conference hashtag","text":"Next, discuss enriching data ’ve collected TAGS pull_tweet_data() function. TAGS archive imported R, {tidytags} allows gather quite bit information related collected tweets pull_tweet_data() function. function uses {rtweet} package (via rtweet::lookup_tweets()) query Twitter API. Using {rtweet} requires Twitter API keys associated approved developer account. Fortunately, {rtweet} vignette, “Obtaining using access tokens” (vignette(\"auth\", package = \"rtweet\")), provides thorough guide obtaining Twitter API keys. help getting Twitter API keys, see “Getting started tidytags” vignette (vignette(\"setup\", package = \"tidytags\")), specifically Pain Point #2. Note dataset often contain fewer rows running pull_tweet_data(). rtweet::lookup_tweets() searching tweet IDs currently available. tweets deleted made “protected” (.e., private) since TAGS first collected dropped dataset. Rather view limitation, see asset help ensure data better reflects intentions accounts whose tweets collected (see Fiesler & Proferes, 2018). , demonstrate two different ways using pull_tweet_data(). first method query Twitter API tweet ID numbers id_str column returned {rtweet}. However, limitation TAGS numbers column often corrupted Google Sheets considers large numbers (instead character strings) rounds putting exponential form. results first method stored variable example_after_rtweet_A . second method pulls tweet ID numbers tweet URLs. example, tweet URL https://twitter.com/tweet__example/status/1176592704647716864 tweet ID 1176592704647716864. results second method stored variable example_after_rtweet_B . vignette run Nov 19 21, TAGS tracker collected 18 variables associated 2564 tweets. first method searching id_str collected 90 variables associated 2030 tweets. second method using ‘tidytags::get_char_tweet_ids()’ collected 90 variables associated 2030 tweets. Notice many variables dataset using pull_tweet_data(), many tweets dataset using second method. found process storing retrieving tweet IDs, long string numbers can sometimes interpreted object type double (.e., numeric) subsequently converted scientific notation form. loses specific identifying use string numerical digits. Therefore, strongly recommend second method, obtaining tweet IDs tweet URL, included get_char_tweet_ids() internal function {tidytags} package. built-default pull_tweet_data() simply enter dataframe retrieved read_tags() implement second method, retrieving metadata starting tweet URLs. , pull_tweet_data(read_tags(example_url)). Take quick look result, viewed glimpse() function {dplyr} package: point, purpose {tidytags} restated. TAGS tweet trackers easily set maintained, excellent job passively collecting tweets time. instance, example TAGS tracker demo collected thousands tweets related AECT 2019 annual convention since September 30, 2019. contrast, running query now using rtweet::search_tweets() limited Twitter’s API, meaning {rtweet} search can go back time 6-9 days, limited returning 18,000 tweets per query. , interested tweets AECT 2019, today get almost meaningful data using {rtweet} alone. can see {rtweet} search #AECT19 tweets run today returns 0tweets. sum, although TAGS tracker great easily collecting tweets time (breadth), lacks depth terms metadata related gathered tweets. Specifically, TAGS returns information 18 variables; contrast, {rtweet} returns information 90 variables. Thus, package {tidytags} brings together breadth TAGS depth {rtweet}.","code":"example_after_rtweet_A <- pull_tweet_data(id_vector = example_df_all$id_str) example_after_rtweet_B <- pull_tweet_data(url_vector = example_df_all$status_url) example_after_rtweet <- pull_tweet_data(read_tags(tags_url)) dplyr::glimpse(example_after_rtweet) #> Rows: 2,030 #> Columns: 90 #> $ user_id                 <chr> \"14215524\", \"14215524\", \"14215524\", \"14215524\", \"14215524\", … #> $ status_id               <chr> \"1225122317849657345\", \"1187817883381796864\", \"1187960612695… #> $ created_at              <dttm> 2020-02-05 18:21:36, 2019-10-25 19:47:06, 2019-10-26 05:14:… #> $ screen_name             <chr> \"tadousay\", \"tadousay\", \"tadousay\", \"tadousay\", \"tadousay\", … #> $ text                    <chr> \"Many thanks to @AECTTechTrends for supporting our @gsa_aect… #> $ source                  <chr> \"TweetDeck\", \"TweetDeck\", \"IFTTT\", \"Twitter for Android\", \"I… #> $ display_text_width      <dbl> 268, 284, 89, 95, 137, 75, 103, 270, 280, 62, 188, 136, 132,… #> $ reply_to_status_id      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ reply_to_user_id        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ reply_to_screen_name    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_quote                <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS… #> $ is_retweet              <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS… #> $ favorite_count          <int> 8, 1, 3, 0, 3, 10, 32, 14, 12, 2, 7, 0, 0, 12, 15, 7, 0, 0, … #> $ retweet_count           <int> 2, 0, 0, 0, 0, 0, 4, 7, 0, 0, 2, 1, 1, 3, 2, 0, 1, 6, 5, 3, … #> $ quote_count             <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ reply_count             <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ hashtags                <list> <\"uidaho\", \"UISTEMEdRG\", \"aect\", \"aect20\", \"aect19\">, <\"UId… #> $ symbols                 <list> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ urls_url                <list> \"doi.org/10.1007/s11528…\", \"docs.google.com/forms/d/e/1FAI…… #> $ urls_t.co               <list> \"https://t.co/8MuP9Mza8f\", \"https://t.co/2bRw5YYDA9\", \"http… #> $ urls_expanded_url       <list> \"https://doi.org/10.1007/s11528-020-00477-5\", \"https://docs… #> $ media_url               <list> NA, NA, \"http://pbs.twimg.com/media/EHx74b1W4AY11Kb.jpg\", \"… #> $ media_t.co              <list> NA, NA, \"https://t.co/79CGsiSCHD\", \"https://t.co/aJiDeNQoUp… #> $ media_expanded_url      <list> NA, NA, \"https://twitter.com/tadousay/status/11879606126950… #> $ media_type              <list> NA, NA, \"photo\", \"photo\", \"photo\", \"photo\", \"photo\", \"photo… #> $ ext_media_url           <list> NA, NA, \"http://pbs.twimg.com/media/EHx74b1W4AY11Kb.jpg\", \"… #> $ ext_media_t.co          <list> NA, NA, \"https://t.co/79CGsiSCHD\", \"https://t.co/aJiDeNQoUp… #> $ ext_media_expanded_url  <list> NA, NA, \"https://twitter.com/tadousay/status/11879606126950… #> $ ext_media_type          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ mentions_user_id        <list> <\"804807943\", \"922536306437181440\">, \"2165058337\", NA, NA, … #> $ mentions_screen_name    <list> <\"AECTTechTrends\", \"gsa_aect\">, \"tedaect\", NA, NA, NA, NA, … #> $ lang                    <chr> \"en\", \"en\", \"en\", \"en\", \"en\", \"en\", \"en\", \"en\", \"en\", \"en\", … #> $ quoted_status_id        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ quoted_text             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ quoted_created_at       <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_source           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ quoted_favorite_count   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ quoted_retweet_count    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ quoted_user_id          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ quoted_screen_name      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ quoted_name             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ quoted_followers_count  <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ quoted_friends_count    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ quoted_statuses_count   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ quoted_location         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ quoted_description      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ quoted_verified         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ retweet_status_id       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"118777882718075… #> $ retweet_text            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"#AECT19 #aect19… #> $ retweet_created_at      <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2019-10-25 17:1… #> $ retweet_source          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"TweetDeck\", \"Tw… #> $ retweet_favorite_count  <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 5, 6, NA, NA, NA… #> $ retweet_retweet_count   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, 1, NA, NA, NA… #> $ retweet_user_id         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"11092692\", \"413… #> $ retweet_screen_name     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"gravesle\", \"Fak… #> $ retweet_name            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Dr. Leigh Grave… #> $ retweet_followers_count <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 5988, 95, NA, NA… #> $ retweet_friends_count   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 6521, 116, NA, N… #> $ retweet_statuses_count  <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 47343, 251, NA, … #> $ retweet_location        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Michigan/Galway… #> $ retweet_description     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"I like to share… #> $ retweet_verified        <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, FALSE, FALSE, NA… #> $ place_url               <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ place_name              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ place_full_name         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ place_type              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ country                 <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ country_code            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ geo_coords              <list> <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>,… #> $ coords_coords           <list> <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>,… #> $ bbox_coords             <list> <NA, NA, NA, NA, NA, NA, NA, NA>, <NA, NA, NA, NA, NA, NA, … #> $ status_url              <chr> \"https://twitter.com/tadousay/status/1225122317849657345\", \"… #> $ name                    <chr> \"Dr. Tonia A. Dousay\", \"Dr. Tonia A. Dousay\", \"Dr. Tonia A. … #> $ location                <chr> \"Moscow, ID\", \"Moscow, ID\", \"Moscow, ID\", \"Moscow, ID\", \"Mos… #> $ description             <chr> \"❖ @UIdaho Assoc Prof of #LearningSci ⋄ Assoc Dean of #Accre… #> $ url                     <chr> \"https://t.co/mNe8apZBwK\", \"https://t.co/mNe8apZBwK\", \"https… #> $ protected               <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS… #> $ followers_count         <int> 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, … #> $ friends_count           <int> 1320, 1320, 1320, 1320, 1320, 1320, 1320, 1320, 1320, 1320, … #> $ listed_count            <int> 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, … #> $ statuses_count          <int> 11894, 11894, 11894, 11894, 11894, 11894, 11894, 11894, 1189… #> $ favourites_count        <int> 4232, 4232, 4232, 4232, 4232, 4232, 4232, 4232, 4232, 4232, … #> $ account_created_at      <dttm> 2008-03-25 13:56:07, 2008-03-25 13:56:07, 2008-03-25 13:56:… #> $ verified                <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS… #> $ profile_url             <chr> \"https://t.co/mNe8apZBwK\", \"https://t.co/mNe8apZBwK\", \"https… #> $ profile_expanded_url    <chr> \"http://about.me/tadousay\", \"http://about.me/tadousay\", \"htt… #> $ account_lang            <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ profile_banner_url      <chr> \"https://pbs.twimg.com/profile_banners/14215524/1550516097\",… #> $ profile_background_url  <chr> \"http://abs.twimg.com/images/themes/theme9/bg.gif\", \"http://… #> $ profile_image_url       <chr> \"http://pbs.twimg.com/profile_images/1458504088186884100/6Nd… rtweet_today <-   rtweet::search_tweets(\"#aect19 OR #aect2019 OR #aect19inspired\")"},{"path":"https://docs.ropensci.org/tidytags/articles/tidytags-with-conf-hashtags.html","id":"lookup_many_tweets","dir":"Articles","previous_headings":"","what":"lookup_many_tweets()","title":"Using tidytags with a conference hashtag","text":"Twitter API allows looking 90,000 tweet IDs time, rate limit resets 15 minutes. Hence rtweet::lookup_tweets() return results first 90,000 tweet IDs dataset. function tidytags::lookup_many_tweets() automatically break dataset batches 90,000 tweets, looking one batch per 15 minutes finished. Note lookup_many_tweets() also works datasets fewer 90,000 tweets well. AECT 2019 examples includes fewer 90,000 tweets (lookup_many_tweets() involves waiting 15 minutes batches), include example . However, function can used way pull_tweet_data().","code":""},{"path":"https://docs.ropensci.org/tidytags/articles/tidytags-with-conf-hashtags.html","id":"process_tweets","dir":"Articles","previous_headings":"","what":"process_tweets()","title":"Using tidytags with a conference hashtag","text":"pull_tweet_data() used collect additional information TAGS tweet IDs (case, example_after_rtweet dataframe), {tidytags} function process_tweets() can used calculate additional attributes add dataframe new columns. Specifically, 10 new variables added: word_count, character_count, mentions_count, hashtags_count_api, hashtags_count_regex, has_hashtags, urls_count_api, urls_count_regex, is_reply, is_self_reply. results 100 variables associated collected tweets. Notice now 100 variables associated 2030 tweets. point, depending research questions, may wish calculate descriptive statistics associated tweet data. instance mean number characters per tweet: shows mean number characters per tweet 180.02 (SD = 75.18). , perhaps, mean, median, max number hashtags per tweet useful know: mean number hashtags per tweet 2.16 (SD = 1.52). median 2, maximum number hashtags tweet 12.","code":"example_processed <- process_tweets(example_after_rtweet) mean_char <- round(mean(example_processed$character_count), 2) sd_char <- round(sd(example_processed$character_count), 2) mean_hash <- round(mean(example_processed$hashtags_count_regex), 2) sd_hash <- round(sd(example_processed$hashtags_count_regex), 2) median_hash <- median(example_processed$hashtags_count_regex) max_hash <- max(example_processed$hashtags_count_regex)"},{"path":"https://docs.ropensci.org/tidytags/articles/tidytags-with-conf-hashtags.html","id":"get_url_domain","dir":"Articles","previous_headings":"","what":"get_url_domain()","title":"Using tidytags with a conference hashtag","text":"{tidytags} function get_url_domain() combines expand_urls() function {longurl} package domain() function {urltools} package easily return domain names hyperlinks including tweets. Note using longurl::expand_urls() necessary step Twitter automatically shortens hyperlinks included tweets. example, get_url_domain() finds domain shortened URL “http://bit.ly/2SfWO3K” “aect.org”: may also interest examine websites get linked often dataset. get_url_domain() can combined function base R like table() calculate frequency counts domains present dataset. process useful get picture else Internet tweeters directing readers’ attention. Keep mind, however, process bit slow. Unsurprisingly, dataset, far common domain (September 30, 2020) “twitter.com”, meaning AECT 2019 tweeters linking often Twitter content. common domains included “convention2.allacademic.com” (.e., host conference website, including schedule session information) well “instagram.com” “youtube.com”, tweeters likely shared conference-related content.","code":"short_url <- \"http://bit.ly/2SfWO3K\" get_url_domain(short_url) #> [1] \"aect.org\" example_urls <- purrr::flatten_chr(example_processed$urls_url) example_urls <- example_urls[!is.na(example_urls)] # Remove NA values example_domains <- get_url_domain(example_urls) domain_table <- tibble::as_tibble(table(example_domains)) domain_table_sorted <- dplyr::arrange(domain_table, desc(n)) head(domain_table_sorted, 20) #> # A tibble: 20 × 2 #>    example_domains                 n #>    <chr>                       <int> #>  1 convention2.allacademic.com    23 #>  2 instagram.com                  12 #>  3 youtube.com                     9 #>  4 drive.google.com                7 #>  5 accounts.google.com             6 #>  6 nodexlgraphgallery.org          6 #>  7 docs.google.com                 5 #>  8 flipsnack.com                   5 #>  9 litnet.co.za                    5 #> 10 app.core-apps.com               4 #> 11 apps.apple.com                  4 #> 12 caranorth.com                   4 #> 13 linkedin.com                    4 #> 14 play.google.com                 4 #> 15 springer.com                    4 #> 16 bretsw.github.io                3 #> 17 msu.zoom.us                     3 #> 18 edtechbooks.org                 2 #> 19 twitter.com                     2 #> 20 amazon.com                      1"},{"path":"https://docs.ropensci.org/tidytags/articles/tidytags-with-conf-hashtags.html","id":"geocode_tags","dir":"Articles","previous_headings":"","what":"geocode_tags()","title":"Using tidytags with a conference hashtag","text":"Another area explore tweeters dataset (, least, location self-identify Twitter profiles). {tidytags} makes straightforward geocode_tags() function. Note geocode_tags() used additional metadata retrieved tidytags::pull_tweet_data(). geocode_tags() pulls OpenCage Geocoding API, requires OpenCage Geocoding API Key. can easily secure key OpenCage directly; Quick Start guide offers helpful guidance (read ). key, OpenCage Geocoding API Documentation offers many additional helps. ’re trouble setting OpenCage Geocoding API Key, see “Getting started tidytags” vignette (vignette(\"setup\", package = \"tidytags\")), specifically Pain Point #4. can pair geocode_tags() {mapview} package allow quick, interactive viewing geocoded data; read mapview . many additional R packages can plot coordinates map; choose largely matter personal preference. First, identify unique individuals dataset: , geocode random sample 10% locations geocode_tags() function, takes tibble outputs vector geo-coordinates. Finally, ’s easy visualize data, number packages supporting visualization geo-coordinates. instance, can use mapview() function {mapview} package: point, can view interactive map R environment simply calling example_map.","code":"example_unique_places <-   dplyr::distinct(example_processed, location, .keep_all = TRUE) sample_unique_places <- dplyr::sample_n(example_unique_places, 10) example_geo_coords <- geocode_tags(sample_unique_places) example_geo_coords #> # A tibble: 10 × 103 #>    user_id    status_id  created_at          screen_name  text        source  display_text_wi… #>    <chr>      <chr>      <dttm>              <chr>        <chr>       <chr>              <dbl> #>  1 93868762   118634665… 2019-10-21 18:20:58 jcmadison20… #inspiredm… Twitte…               19 #>  2 28518944   118529238… 2019-10-18 20:31:41 ekowch       AECT Conve… Twitte…              278 #>  3 32396916   120149326… 2019-12-02 13:28:11 ifyouaskbet… Kicking of… Twitte…              140 #>  4 69122603   118659963… 2019-10-22 11:06:13 cmmarqua     For folks … Twitte…              140 #>  5 17883918   118676857… 2019-10-22 22:17:32 veletsianos  May I sugg… TweetD…               67 #>  6 14481157   118689002… 2019-10-23 06:20:08 susiegronse… The ID the… Twitte…              227 #>  7 902231366  118671469… 2019-10-22 18:43:26 EmmaMMercier Wonderful … Twitte…               96 #>  8 21066932   118211936… 2019-10-10 02:23:13 MTroyMartin  Poster rea… Twitte…              118 #>  9 214979874  118756036… 2019-10-25 02:43:50 PaulineMulj… Thank you … Twitte…              225 #> 10 1664133686 118738663… 2019-10-24 15:13:29 ZhongruiYao  Another co… Twitte…              108 #> # … with 96 more variables: reply_to_status_id <chr>, reply_to_user_id <chr>, #> #   reply_to_screen_name <chr>, is_quote <lgl>, is_retweet <lgl>, favorite_count <int>, #> #   retweet_count <int>, quote_count <int>, reply_count <int>, hashtags <list>, #> #   symbols <list>, urls_url <list>, urls_t.co <list>, urls_expanded_url <list>, #> #   media_url <list>, media_t.co <list>, media_expanded_url <list>, media_type <list>, #> #   ext_media_url <list>, ext_media_t.co <list>, ext_media_expanded_url <list>, #> #   ext_media_type <chr>, mentions_user_id <list>, mentions_screen_name <list>, lang <chr>, … if (requireNamespace(\"sf\", quietly = TRUE)) {   locations <-     sf::st_as_sf(       example_geo_coords,       coords = c(x = \"longitude\", y = \"latitude\"),       crs = 4326     ) }  if (requireNamespace(\"mapview\", quietly = TRUE)) {   example_map <- mapview::mapview(locations) }"},{"path":"https://docs.ropensci.org/tidytags/articles/tidytags-with-conf-hashtags.html","id":"filter_by_tweet_type","dir":"Articles","previous_headings":"","what":"filter_by_tweet_type()","title":"Using tidytags with a conference hashtag","text":"function quickly subsets data, returning just tweets type indicated (e.g., filter_by_tweet_type(df, \"reply\") returns reply tweets). filter_by_tweet_type() function can also used look many tweets type present dataset. dataset 2030 tweets, 62 replies, 1065 retweets, 92 quote tweets, 2747 tweets containing mentions.","code":""},{"path":"https://docs.ropensci.org/tidytags/articles/tidytags-with-conf-hashtags.html","id":"get_upstream_tweets","dir":"Articles","previous_headings":"","what":"get_upstream_tweets()","title":"Using tidytags with a conference hashtag","text":"research questions conceptualize tweet dataset conversation affinity space, may useful retrieve add additional tweets. Specifically, TAGS collects tweets contain one keywords text strings. example, TAGS tracker working vignette collected tweets containing keywords: #aect19 #aect2019 #aect19inspired. reasonable approach, researchers’ point view. However, participants following contributing hashtags also see additional tweets “conversations” Twitter connects together tweets reply tweets potentially lengthy reply threads. Tweets reply thread displayed user viewing tweets Twitter’s platform, tweets thread may contain hashtag interest, tweets user’s experience conversation collected TAGS. Additionally, tweets contained reply thread composed TAGS tracker initiated also left dataset. solution problem. Twitter API offers reply_to_status_id column, possible iteratively reconstruct reply threads upstream direction, , retrieving tweets composed earlier replies dataset. include get_upstream_tweets {tidytags} streamline process. also print output iteration demonstrate process progressing. dataset contained 2030 tweets start. Running get_upstream_tweets() added 28 new tweets. Unfortunately, due limitations information given Twitter API, practical retrieve downstream replies, tweets reply thread follow tweet dataset neglect include hashtag keyword.","code":"example_with_upstream <- get_upstream_tweets(example_processed)"},{"path":"https://docs.ropensci.org/tidytags/articles/tidytags-with-conf-hashtags.html","id":"create_edgelist","dir":"Articles","previous_headings":"","what":"create_edgelist()","title":"Using tidytags with a conference hashtag","text":"Another useful approach social media research social network analysis. Getting started social network analysis simple producing edgelist, two-column dataframe listing senders receivers. edgelist gives complete accounting interacting . Twitter, complicated somewhat number ways user able interact someone else, namely, replying, retweeting, quote tweeting, mentioning, liking tweets. {tidytags} function create_edgelist() uses filter_by_tweet_type() create edgelist takes account four types interaction. create_edgelist() returns dataframe three columns: two sender receiver Twitter handles, third column listing edge type (.e., form interaction). default create_edgelist() create edgelist possible interactions, focusing one type interaction easily accomplished well (e.g., looking interactions replies using create_edgelist(df, \"reply\")). Run create_edgelist() completing get_upstream_tweets() complete picture interactions. can easily visualize edgelist sociogram using {tidygraph} {ggraph} packages. First, create graph object using {tidygraph}: plot using {ggraph}:  Running create_edgelist() also provides simple way re-look many tweets type present dataset, using count() function {dplyr}. Note create_edgelist() yet accept type = \"like\" parameter due limitations information provided Twitter API.","code":"example_edgelist <- create_edgelist(example_with_upstream) head(example_edgelist, 20) #> # A tibble: 20 × 3 #>    sender         receiver        edge_type #>    <chr>          <chr>           <chr>     #>  1 lbukunAA       lbukunAA        reply     #>  2 bretsw         bretsw          reply     #>  3 bretsw         FakeBobGagne    reply     #>  4 bretsw         bretsw          reply     #>  5 bretsw         eromerohall     reply     #>  6 bretsw         bretsw          reply     #>  7 AECT           jmenglund03     reply     #>  8 correia65      AnnaRoseLeach   reply     #>  9 caranorth11    FredWBaker      reply     #> 10 PaulineMuljana AmyLomellini_ID reply     #> 11 PaulineMuljana soniastic       reply     #> 12 PaulineMuljana robmoore3       reply     #> 13 PaulineMuljana WEHSLibrary     reply     #> 14 PaulineMuljana tintinluo       reply     #> 15 nicolapallitt  eromerohall     reply     #> 16 nicolapallitt  aectclt         reply     #> 17 michaelmgrant  robmoore3       reply     #> 18 michaelmgrant  DKSch           reply     #> 19 michaelmgrant  nicolapallitt   reply     #> 20 michaelmgrant  EdTech_UofSC    reply if (requireNamespace(\"tidygraph\", quietly = TRUE) {   example_graph <-     tidygraph::as_tbl_graph(example_edgelist)   example_graph <-     dplyr::mutate(example_graph,                   popularity = tidygraph::centrality_degree(mode = 'in')) } if (requireNamespace(\"ggraph\", quietly = TRUE) &     requireNamespace(\"ggplot2\", quietly = TRUE) ) {   ggraph::ggraph(example_graph, layout = 'kk') +     ggraph::geom_edge_arc(alpha = .2,                            width = .5,                            strength = .5,                            edge_colour = 'steelblue'     ) +     ggraph::geom_node_point(alpha = .4, ggplot2::aes(size = popularity)) +     ggplot2::scale_size(range = c(1,10)) } dplyr::count(example_edgelist, edge_type, sort = TRUE) #> # A tibble: 4 × 2 #>   edge_type       n #>   <chr>       <int> #> 1 mention      2785 #> 2 retweet      1065 #> 3 quote-tweet    99 #> 4 reply          71"},{"path":"https://docs.ropensci.org/tidytags/articles/tidytags-with-conf-hashtags.html","id":"add_users_data","dir":"Articles","previous_headings":"","what":"add_users_data()","title":"Using tidytags with a conference hashtag","text":"Finally, {tidytags} also functionality add user-level data edgelist function add_users_data(). additional features useful taking inferential approach social network analysis, building influence selection models.","code":"example_senders_receivers_data <- add_users_data(example_edgelist) dplyr::glimpse(example_senders_receivers_data) #> Rows: 4,020 #> Columns: 181 #> $ sender                           <chr> \"lbukunAA\", \"bretsw\", \"bretsw\", \"bretsw\", \"bretsw\",… #> $ receiver                         <chr> \"lbukunAA\", \"bretsw\", \"FakeBobGagne\", \"bretsw\", \"er… #> $ edge_type                        <chr> \"reply\", \"reply\", \"reply\", \"reply\", \"reply\", \"reply… #> $ user_id_sender                   <chr> \"2950104673\", \"53167706\", \"53167706\", \"53167706\", \"… #> $ status_id_sender                 <chr> \"1453003605691314182\", \"1461476051587063811\", \"1461… #> $ created_at_sender                <dttm> 2021-10-26 14:20:29, 2021-11-18 23:26:58, 2021-11-… #> $ text_sender                      <chr> \"Join us for the ETC Research Lab's 2021 Speakers S… #> $ source_sender                    <chr> \"Twitter for Android\", \"Twitter for iPhone\", \"Twitt… #> $ display_text_width_sender        <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ reply_to_status_id_sender        <chr> NA, NA, NA, NA, NA, NA, NA, \"1460640595257573376\", … #> $ reply_to_user_id_sender          <chr> NA, NA, NA, NA, NA, NA, NA, \"32417534\", NA, \"335462… #> $ reply_to_screen_name_sender      <chr> NA, NA, NA, NA, NA, NA, NA, \"lucysantosgreen\", NA, … #> $ is_quote_sender                  <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA… #> $ is_retweet_sender                <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FA… #> $ favorite_count_sender            <int> 0, 0, 0, 0, 0, 0, 0, 0, 33, 1, 1, 1, 1, 1, 0, 0, 0,… #> $ retweet_count_sender             <int> 6, 4, 4, 4, 4, 4, 2, 0, 1, 0, 0, 0, 0, 0, 11, 11, 3… #> $ quote_count_sender               <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ reply_count_sender               <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ hashtags_sender                  <list> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… #> $ symbols_sender                   <list> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… #> $ urls_url_sender                  <list> NA, NA, NA, NA, NA, NA, NA, NA, \"twitter.com/i/web… #> $ urls_t.co_sender                 <list> NA, NA, NA, NA, NA, NA, NA, NA, \"https://t.co/G5Ji… #> $ urls_expanded_url_sender         <list> NA, NA, NA, NA, NA, NA, NA, NA, \"https://twitter.c… #> $ media_url_sender                 <list> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… #> $ media_t.co_sender                <list> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… #> $ media_expanded_url_sender        <list> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… #> $ media_type_sender                <list> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… #> $ ext_media_url_sender             <list> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… #> $ ext_media_t.co_sender            <list> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… #> $ ext_media_expanded_url_sender    <list> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… #> $ ext_media_type_sender            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ mentions_user_id_sender          <list> \"1613204671\", <\"17659421\", \"1156290361951756288\">,… #> $ mentions_screen_name_sender      <list> \"okstate_etc\", <\"fsueducation\", \"2020FLTOY\">, <\"fs… #> $ lang_sender                      <chr> \"en\", \"en\", \"en\", \"en\", \"en\", \"en\", \"en\", \"en\", \"en… #> $ quoted_status_id_sender          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_text_sender               <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_created_at_sender         <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… #> $ quoted_source_sender             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_favorite_count_sender     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_retweet_count_sender      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_user_id_sender            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_screen_name_sender        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_name_sender               <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_followers_count_sender    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_friends_count_sender      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_statuses_count_sender     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_location_sender           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_description_sender        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_verified_sender           <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_status_id_sender         <chr> \"1453003310131294219\", \"1461432541181849606\", \"1461… #> $ retweet_text_sender              <chr> \"Join us for the ETC Research Lab's 2021 Speakers S… #> $ retweet_created_at_sender        <dttm> 2021-10-26 14:19:19, 2021-11-18 20:34:04, 2021-11-… #> $ retweet_source_sender            <chr> \"Twitter Web App\", \"Sprout Social\", \"Sprout Social\"… #> $ retweet_favorite_count_sender    <int> 3, 18, 18, 18, 18, 18, 9, NA, NA, NA, NA, NA, NA, N… #> $ retweet_retweet_count_sender     <int> 6, 4, 4, 4, 4, 4, 2, NA, NA, NA, NA, NA, NA, NA, 11… #> $ retweet_user_id_sender           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_screen_name_sender       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_name_sender              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_followers_count_sender   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_friends_count_sender     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_statuses_count_sender    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_location_sender          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_description_sender       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_verified_sender          <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ place_url_sender                 <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ place_name_sender                <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ place_full_name_sender           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ place_type_sender                <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ country_sender                   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ country_code_sender              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ geo_coords_sender                <list> <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, … #> $ coords_coords_sender             <list> <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, … #> $ bbox_coords_sender               <list> <NA, NA, NA, NA, NA, NA, NA, NA>, <NA, NA, NA, NA,… #> $ status_url_sender                <chr> \"https://twitter.com/NA/status/1453003605691314182\"… #> $ name_sender                      <chr> \"Ayodeji Ibukun\", \"Dr. Bret Staudt Willet\", \"Dr. Br… #> $ location_sender                  <chr> \"Oklahoma, USA\", \"Tallahassee, FL\", \"Tallahassee, F… #> $ description_sender               <chr> \"B.Engrg MS MNSE\", \"(he/him) Assistant Professor @I… #> $ url_sender                       <chr> \"https://t.co/kVfuPQQfYs\", \"https://t.co/9lV9hWdb9F… #> $ protected_sender                 <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA… #> $ followers_count_sender           <int> 45, 2100, 2100, 2100, 2100, 2100, 4398, 2796, 7926,… #> $ friends_count_sender             <int> 475, 2678, 2678, 2678, 2678, 2678, 555, 2299, 3868,… #> $ listed_count_sender              <int> 0, 55, 55, 55, 55, 55, 125, 26, 200, 5, 5, 5, 5, 5,… #> $ statuses_count_sender            <int> 131, 7007, 7007, 7007, 7007, 7007, 3076, 589, 20509… #> $ favourites_count_sender          <int> 609, 9678, 9678, 9678, 9678, 9678, 3425, 7868, 3570… #> $ account_created_at_sender        <dttm> 2014-12-29 12:06:33, 2009-07-02 19:51:43, 2009-07-… #> $ verified_sender                  <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA… #> $ profile_url_sender               <chr> \"https://t.co/kVfuPQQfYs\", \"https://t.co/9lV9hWdb9F… #> $ profile_expanded_url_sender      <chr> \"http://www.ayoibukun.com\", \"http://bretsw.com\", \"h… #> $ account_lang_sender              <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ profile_banner_url_sender        <chr> \"https://pbs.twimg.com/profile_banners/2950104673/1… #> $ profile_background_url_sender    <chr> \"http://abs.twimg.com/images/themes/theme1/bg.png\",… #> $ profile_image_url_sender         <chr> \"http://pbs.twimg.com/profile_images/10862752062748… #> $ user_id_receiver                 <chr> \"2950104673\", \"53167706\", \"4130346912\", \"53167706\",… #> $ status_id_receiver               <chr> \"1453003605691314182\", \"1461476051587063811\", \"1187… #> $ created_at_receiver              <dttm> 2021-10-26 14:20:29, 2021-11-18 23:26:58, 2019-10-… #> $ text_receiver                    <chr> \"Join us for the ETC Research Lab's 2021 Speakers S… #> $ source_receiver                  <chr> \"Twitter for Android\", \"Twitter for iPhone\", \"Twitt… #> $ display_text_width_receiver      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ reply_to_status_id_receiver      <chr> NA, NA, NA, NA, \"1461701211699261462\", NA, NA, NA, … #> $ reply_to_user_id_receiver        <chr> NA, NA, NA, NA, \"918747876\", NA, NA, NA, \"126059707… #> $ reply_to_screen_name_receiver    <chr> NA, NA, NA, NA, \"eromerohall\", NA, NA, NA, \"The_MoB… #> $ is_quote_receiver                <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA… #> $ is_retweet_receiver              <lgl> TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, … #> $ favorite_count_receiver          <int> 0, 0, 3, 0, 4, 0, 0, 0, 1, 0, 3, 0, 2, 0, 4, 0, 0, … #> $ retweet_count_receiver           <int> 6, 4, 1, 4, 1, 4, 4, 0, 0, 16, 0, 0, 0, 0, 1, 2, 0,… #> $ quote_count_receiver             <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ reply_count_receiver             <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ hashtags_receiver                <list> NA, NA, \"aect19\", NA, NA, NA, NA, <\"adultliteracy\"… #> $ symbols_receiver                 <list> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… #> $ urls_url_receiver                <list> NA, NA, NA, NA, \"twitter.com/i/web/status/1…\", NA,… #> $ urls_t.co_receiver               <list> NA, NA, NA, NA, \"https://t.co/NBBR2LQ78Z\", NA, \"ht… #> $ urls_expanded_url_receiver       <list> NA, NA, NA, NA, \"https://twitter.com/i/web/status/… #> $ media_url_receiver               <list> NA, NA, \"http://pbs.twimg.com/tweet_video_thumb/EH… #> $ media_t.co_receiver              <list> NA, NA, \"https://t.co/oOFVcSXkQB\", NA, NA, NA, NA,… #> $ media_expanded_url_receiver      <list> NA, NA, \"https://twitter.com/FakeBobGagne/status/1… #> $ media_type_receiver              <list> NA, NA, \"photo\", NA, NA, NA, NA, NA, NA, NA, NA, N… #> $ ext_media_url_receiver           <list> NA, NA, \"http://pbs.twimg.com/tweet_video_thumb/EH… #> $ ext_media_t.co_receiver          <list> NA, NA, \"https://t.co/oOFVcSXkQB\", NA, NA, NA, NA,… #> $ ext_media_expanded_url_receiver  <list> NA, NA, \"https://twitter.com/FakeBobGagne/status/1… #> $ ext_media_type_receiver          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ mentions_user_id_receiver        <list> \"1613204671\", <\"17659421\", \"1156290361951756288\">,… #> $ mentions_screen_name_receiver    <list> \"okstate_etc\", <\"fsueducation\", \"2020FLTOY\">, NA, … #> $ lang_receiver                    <chr> \"en\", \"en\", \"en\", \"en\", \"en\", \"en\", \"en\", \"en\", \"en… #> $ quoted_status_id_receiver        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_text_receiver             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_created_at_receiver       <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… #> $ quoted_source_receiver           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_favorite_count_receiver   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_retweet_count_receiver    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_user_id_receiver          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_screen_name_receiver      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_name_receiver             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_followers_count_receiver  <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_friends_count_receiver    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_statuses_count_receiver   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_location_receiver         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_description_receiver      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ quoted_verified_receiver         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_status_id_receiver       <chr> \"1453003310131294219\", \"1461432541181849606\", NA, \"… #> $ retweet_text_receiver            <chr> \"Join us for the ETC Research Lab's 2021 Speakers S… #> $ retweet_created_at_receiver      <dttm> 2021-10-26 14:19:19, 2021-11-18 20:34:04, NA, 2021… #> $ retweet_source_receiver          <chr> \"Twitter Web App\", \"Sprout Social\", NA, \"Sprout Soc… #> $ retweet_favorite_count_receiver  <int> 3, 18, NA, 18, NA, 18, 13, NA, NA, 45, NA, NA, NA, … #> $ retweet_retweet_count_receiver   <int> 6, 4, NA, 4, NA, 4, 4, NA, NA, 16, NA, NA, NA, NA, … #> $ retweet_user_id_receiver         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_screen_name_receiver     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_name_receiver            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_followers_count_receiver <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_friends_count_receiver   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_statuses_count_receiver  <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_location_receiver        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_description_receiver     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ retweet_verified_receiver        <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ place_url_receiver               <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ place_name_receiver              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ place_full_name_receiver         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ place_type_receiver              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ country_receiver                 <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ country_code_receiver            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ geo_coords_receiver              <list> <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, … #> $ coords_coords_receiver           <list> <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, … #> $ bbox_coords_receiver             <list> <NA, NA, NA, NA, NA, NA, NA, NA>, <NA, NA, NA, NA,… #> $ status_url_receiver              <chr> \"https://twitter.com/NA/status/1453003605691314182\"… #> $ name_receiver                    <chr> \"Ayodeji Ibukun\", \"Dr. Bret Staudt Willet\", \"FakeBo… #> $ location_receiver                <chr> \"Oklahoma, USA\", \"Tallahassee, FL\", \"\", \"Tallahasse… #> $ description_receiver             <chr> \"B.Engrg MS MNSE\", \"(he/him) Assistant Professor @I… #> $ url_receiver                     <chr> \"https://t.co/kVfuPQQfYs\", \"https://t.co/9lV9hWdb9F… #> $ protected_receiver               <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA… #> $ followers_count_receiver         <int> 45, 2100, 95, 2100, 1515, 2100, 667, 590, 1393, 559… #> $ friends_count_receiver           <int> 475, 2678, 116, 2678, 1125, 2678, 620, 529, 1482, 9… #> $ listed_count_receiver            <int> 0, 55, 2, 55, 90, 55, 72, 14, 108, 0, 0, 54, 18, 9,… #> $ statuses_count_receiver          <int> 131, 7007, 251, 7007, 341, 7007, 2894, 2688, 18991,… #> $ favourites_count_receiver        <int> 609, 9678, 133, 9678, 7073, 9678, 2053, 1790, 24298… #> $ account_created_at_receiver      <dttm> 2014-12-29 12:06:33, 2009-07-02 19:51:43, 2015-11-… #> $ verified_receiver                <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA… #> $ profile_url_receiver             <chr> \"https://t.co/kVfuPQQfYs\", \"https://t.co/9lV9hWdb9F… #> $ profile_expanded_url_receiver    <chr> \"http://www.ayoibukun.com\", \"http://bretsw.com\", NA… #> $ account_lang_receiver            <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ profile_banner_url_receiver      <chr> \"https://pbs.twimg.com/profile_banners/2950104673/1… #> $ profile_background_url_receiver  <chr> \"http://abs.twimg.com/images/themes/theme1/bg.png\",… #> $ profile_image_url_receiver       <chr> \"http://pbs.twimg.com/profile_images/10862752062748…"},{"path":"https://docs.ropensci.org/tidytags/articles/tidytags-with-conf-hashtags.html","id":"getting-help","dir":"Articles","previous_headings":"","what":"Getting help","title":"Using tidytags with a conference hashtag","text":"{tidytags} still work progress, fully expect still bugs work functions document better. find issue, question, think something really wish {tidytags} , don’t hesitate email Bret reach Twitter: @bretsw @jrosenberg6432. can also submit issue Github. may also wish try general troubleshooting strategies: Identify causing problem “Unplug plug back ” - restart R, close reopen R RStudio Community - https://community.rstudio.com/ (highly recommended!) Twitter hashtag: #rstats General strategies learning : https://datascienceineducation.com/c17.html","code":""},{"path":"https://docs.ropensci.org/tidytags/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"K. Bret Staudt Willet. Author, maintainer. Joshua M. Rosenberg. Author. Lluís Revilla Sancho. Reviewer. Marion Louveaux. Reviewer.","code":""},{"path":"https://docs.ropensci.org/tidytags/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Staudt Willet, K. B., & Rosenberg, J. M. (2022). tidytags: Importing analyzing Twitter data collected Twitter Archiving Google Sheets. https://github.com/ropensci/tidytags","code":"@Manual{tidytags-package,   title = {tidytags: Importing and analyzing Twitter data collected with Twitter Archiving Google Sheets},   author = {K. Bret Staudt Willet and Joshua M. Rosenberg},   year = {2022}, }"},{"path":[]},{"path":[]},{"path":[]},{"path":"https://docs.ropensci.org/tidytags/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Importing and Analyzing Twitter Data Collected with Twitter Archiving Google Sheets","text":"purpose tidytags make collection Twitter data accessible robust. tidytags retrieves tweet data collected Twitter Archiving Google Sheet (TAGS), gets additional metadata Twitter via rtweet R package, OpenCage using opencage R package, provides additional functions facilitate systematic yet flexible analyses data Twitter. TAGS based Google spreadsheets. TAGS tracker continuously collects tweets Twitter, based predefined search criteria collection frequency. short, tidytags first uses TAGS easily collect tweet ID numbers uses R package rtweet re-query Twitter API collect additional metadata. tidytags also introduces functions developed facilitate systematic yet flexible analyses data Twitter. also interfaces several packages, including opencage package, geocode locations Twitter users based biographies. Two vignettes illustrate setup use package: Getting started tidytags (vignette(\"setup\", package = \"tidytags\")) Using tidytags conference hashtag (vignette(\"tidytags--conf-hashtags\", package = \"tidytags\"))","code":""},{"path":"https://docs.ropensci.org/tidytags/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Importing and Analyzing Twitter Data Collected with Twitter Archiving Google Sheets","text":"can install tidytags R-universe: installed, use library() function load tidytags:","code":"install.packages(\"tidytags\", repos = \"https://ropensci.r-universe.dev\") library(tidytags)"},{"path":"https://docs.ropensci.org/tidytags/index.html","id":"setup","dir":"","previous_headings":"","what":"Setup","title":"Importing and Analyzing Twitter Data Collected with Twitter Archiving Google Sheets","text":"help initial tidytags setup, see Getting started tidytags vignette (vignette(\"setup\", package = \"tidytags\")). Specifically, guide offers help four key tasks: Making sure TAGS tracker can accessed Getting storing Google API key Getting storing Twitter API tokens Getting storing OpenCage Geocoding API key","code":""},{"path":"https://docs.ropensci.org/tidytags/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Importing and Analyzing Twitter Data Collected with Twitter Archiving Google Sheets","text":"test tidytags package, can use openly shared TAGS tracker collecting tweets associated AECT 2019 since September 30, 2019. TAGS tracker used Using tidytags conference hashtag vignette (vignette(\"tidytags--conf-hashtags\", package = \"tidytags\")).","code":""},{"path":[]},{"path":"https://docs.ropensci.org/tidytags/index.html","id":"read_tags","dir":"","previous_headings":"Core Functions","what":"read_tags()","title":"Importing and Analyzing Twitter Data Collected with Twitter Archiving Google Sheets","text":"basic level, tidytags allows import data Twitter Archiving Google Sheet (TAGS) R. done googlesheets4 R package. One requirement using googlesheets4 package TAGS tracker “published web.” See Getting started tidytags vignette (vignette(\"setup\", package = \"tidytags\")), Pain Point #1, need help . TAGS tracker published web, can import TAGS archive R using read_tags(). See Getting started tidytags vignette (vignette(\"setup\", package = \"tidytags\")), Pain Point #2, set API access Google Sheets like TAGS tracker.","code":"example_tags <- \"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\" tags_data <- read_tags(example_tags) head(tags_data) #> # A tibble: 6 × 18 #>   id_str          from_user text  created_at time                geo_coordinates #>   <chr>           <chr>     <chr> <chr>      <dttm>              <chr>           #> 1 12519543127728… Harriet9… \"RT … Sun Apr 1… 2020-04-19 20:22:23 <NA>            #> 2 12480641632110… Patrick8… \"RT … Thu Apr 0… 2020-04-09 02:44:19 <NA>            #> 3 12342069467328… ELTAugus… \"RT … Sun Mar 0… 2020-03-01 20:00:40 <NA>            #> 4 12294053501781… gsa_aect  \"RT … Mon Feb 1… 2020-02-17 14:00:50 <NA>            #> 5 12276522438700… fcis_iu   \"Giv… Wed Feb 1… 2020-02-12 17:54:38 <NA>            #> 6 12255051874539… Stauffer… \"RT … Thu Feb 0… 2020-02-06 19:43:00 <NA>            #> # … with 12 more variables: user_lang <lgl>, in_reply_to_user_id_str <chr>, #> #   in_reply_to_screen_name <chr>, from_user_id_str <chr>, #> #   in_reply_to_status_id_str <chr>, source <chr>, profile_image_url <chr>, #> #   user_followers_count <dbl>, user_friends_count <dbl>, user_location <chr>, #> #   status_url <chr>, entities_str <chr>"},{"path":"https://docs.ropensci.org/tidytags/index.html","id":"pull_tweet_data","dir":"","previous_headings":"Core Functions","what":"pull_tweet_data()","title":"Importing and Analyzing Twitter Data Collected with Twitter Archiving Google Sheets","text":"TAGS archive imported R, tidytags allows gather quite bit information related collected tweets pull_tweet_data() function. function uses rtweet package (via rtweet::lookup_tweets()) query Twitter API. process requires Twitter API keys associated approved Twitter developer account. See Getting started tidytags vignette (vignette(\"setup\", package = \"tidytags\")), Pain Point #3, need help .","code":"expanded_metadata <- pull_tweet_data(tags_data, n = 10) expanded_metadata #> # A tibble: 7 × 90 #>   user_id             status_id     created_at          screen_name text  source #>   <chr>               <chr>         <dttm>              <chr>       <chr> <chr>  #> 1 14215524            122512231784… 2020-02-05 18:21:36 tadousay    \"Man… Tweet… #> 2 922536306437181440  121975838643… 2020-01-21 23:07:15 gsa_aect    \"The… Tweet… #> 3 922536306437181440  122940535017… 2020-02-17 14:00:51 gsa_aect    \"Man… Tweet… #> 4 1251951804398669825 125195431277… 2020-04-19 19:22:23 Harriet961… \"Con… Twitt… #> 5 1088189033266798598 121904357455… 2020-01-19 23:46:51 aectddl     \"The… Twitt… #> 6 3294167372          123420694673… 2020-03-01 20:00:41 ELTAugusta  \"Rem… Twitt… #> 7 804807943           122513787992… 2020-02-05 19:23:27 AECTTechTr… \"Man… Twitt… #> # … with 84 more variables: display_text_width <dbl>, reply_to_status_id <lgl>, #> #   reply_to_user_id <lgl>, reply_to_screen_name <lgl>, is_quote <lgl>, #> #   is_retweet <lgl>, favorite_count <int>, retweet_count <int>, #> #   quote_count <int>, reply_count <int>, hashtags <list>, symbols <list>, #> #   urls_url <list>, urls_t.co <list>, urls_expanded_url <list>, #> #   media_url <list>, media_t.co <list>, media_expanded_url <list>, #> #   media_type <list>, ext_media_url <list>, ext_media_t.co <list>, …"},{"path":"https://docs.ropensci.org/tidytags/index.html","id":"workflow","dir":"","previous_headings":"","what":"Workflow","title":"Importing and Analyzing Twitter Data Collected with Twitter Archiving Google Sheets","text":"following diagram represents functions included tidytags package may work together. presented figure .","code":""},{"path":"https://docs.ropensci.org/tidytags/index.html","id":"learning-more-about-tidytags","dir":"","previous_headings":"","what":"Learning More About tidytags","title":"Importing and Analyzing Twitter Data Collected with Twitter Archiving Google Sheets","text":"walkthrough numerous additional tidytags functions, see Using tidytags conference hashtag vignette (vignette(\"tidytags--conf-hashtags\", package = \"tidytags\")).","code":""},{"path":"https://docs.ropensci.org/tidytags/index.html","id":"getting-help","dir":"","previous_headings":"","what":"Getting Help","title":"Importing and Analyzing Twitter Data Collected with Twitter Archiving Google Sheets","text":"{tidytags} still work progress, fully expect still bugs work functions document better. find issue, question, think something really wish {tidytags} , don’t hesitate email Bret reach Twitter: @bretsw @jrosenberg6432. can also submit issue Github. may also wish try general troubleshooting strategies: Identify causing problem “Unplug plug back ” - restart R, close reopen R RStudio Community - https://community.rstudio.com/ (highly recommended!) Twitter hashtag: #rstats General strategies learning : https://datascienceineducation.com/c17.html","code":""},{"path":"https://docs.ropensci.org/tidytags/index.html","id":"considerations-related-to-ethics-data-privacy-and-human-subjects-research","dir":"","previous_headings":"","what":"Considerations Related to Ethics, Data Privacy, and Human Subjects Research","title":"Importing and Analyzing Twitter Data Collected with Twitter Archiving Google Sheets","text":"{tidytags} used strict accordance Twitter’s developer terms. Although Institutional Review Boards (IRBs) consider Twitter data {tidytags} analyzes necessarily human subjects research, remain ethical considerations pertaining use {tidytags} package discussed. Even {tidytags} use research purposes (IRB determines study human subjects research), “release personally identifiable sensitive data potentially harmful,” noted rOpenSci Packages guide. Therefore, although can collect Twitter data (can use {tidytags} analyze ), urge care thoughtfulness regarding analyze data communicate results. short, please remember () data collect may people—people may like idea data analyzed included research. recommend Association Internet Researchers’ (AoIR) resources related conducting analyses ethical ways working data people. AoIR’s ethical guidelines may especially helpful navigating tensions related collecting, analyzing, sharing social media data.","code":""},{"path":"https://docs.ropensci.org/tidytags/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Importing and Analyzing Twitter Data Collected with Twitter Archiving Google Sheets","text":"encounter obvious bug already active issue, please create new issue code used (preferably reproducible example) GitHub. like become involved contributor, please read Contributing Guide.","code":""},{"path":"https://docs.ropensci.org/tidytags/index.html","id":"contributor-code-of-conduct","dir":"","previous_headings":"Contributing","what":"Contributor Code of Conduct","title":"Importing and Analyzing Twitter Data Collected with Twitter Archiving Google Sheets","text":"Please note package released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://docs.ropensci.org/tidytags/index.html","id":"how-to-cite-this-package-in-publications","dir":"","previous_headings":"","what":"How to Cite This Package in Publications","title":"Importing and Analyzing Twitter Data Collected with Twitter Archiving Google Sheets","text":"can cite package like : “collected, processed, analyzed Twitter data using tidytags R package (Staudt Willet & Rosenberg, 2022)”. full bibliographic reference include reference list: Staudt Willet, K. B., & Rosenberg, J. M. (2022). tidytags: Importing analyzing Twitter data collected Twitter Archiving Google Sheets. https://github.com/ropensci/tidytags","code":""},{"path":"https://docs.ropensci.org/tidytags/index.html","id":"license-license","dir":"","previous_headings":"","what":"License","title":"Importing and Analyzing Twitter Data Collected with Twitter Archiving Google Sheets","text":"tidytags package licensed MIT License. background chose license, read chapter R package licensing.","code":""},{"path":"https://docs.ropensci.org/tidytags/paper.html","id":null,"dir":"","previous_headings":"","what":"Summary","title":"Summary","text":"tidytags R package coordinates simplicity collecting tweets time Twitter Archiving Google Sheet TAGS tweet collector [@hawksey2016] utility rtweet R package [@kearney2019] processing preparing additional Twitter metadata. tidytags also introduces functions facilitate systematic yet flexible analyses data Twitter.","code":""},{"path":"https://docs.ropensci.org/tidytags/paper.html","id":"statement-of-need","dir":"","previous_headings":"","what":"Statement of Need","title":"Summary","text":"essential component understanding behavior across social sciences study actions artifacts group members time. Social media platforms Twitter context inquiry analysis variety topics temporal component. instance, online communities often struggle attrition lack commitment, beneficial understand users continue sustain participation others gradually drop [@arslan_et_al2021; @xing_gao2018]. Also, scholars’ social media use interwoven changes personal lives societal transitions, social media practices must studied time [@veletsianos_et_al2019]. Twitter data best collected moment produced. Full access Twitter data limited platform’s API, particularly terms retrieving data week two prior time collection. instance, researcher using Twitter API summer 2020 search tweets 2019 conference Association Educational Communication & Technology, AECT using hashtags #AECT19 #AECTinspired able readily access tweets time convention (occurred fall 2019). Accessing historical content Twitter can difficult expensive; impossible, real obstacles. Academic researchers got boost January 2021, Twitter launched Academic Research product track updated Twitter API [@tornes_trujillo2021]. new feature provides nearly unlimited (cap 10 million queries resets every month) access Twitter API researchers confirm academic credentials scholarly purpose project. everyone else, third-party companies collect historical Twitter data make available researchers right price, approach can become expensive. also technical solutions collect past tweets web scraping, require advanced technical skills risk likely violation Twitter’s Terms Service agreements. Meanwhile, obstacles time travel familiar enough need repeated . Even navigating challenges retrieving historical Twitter data, task collecting --moment social media data often requires extent technical skill may dissuade social scientists even getting started. However, interested Twitter data, relatively straightforward beginner-level solution use Twitter Archiving Google Sheet TAGS tweet collector [@hawksey2016] . Getting started TAGS simple setting new Google Sheet, automatically query Twitter API keyword search every hour going forward. However, although TAGS provides several advantages data collection, important limitations related data analysis. First, Google Sheets environment conducive statistical analysis beyond basic calculations, Additionally, TAGS returns limited metadata compared available Twitter API: approximately 20% categories information. Specifically, TAGS tweet collector returns time, sender, text tweets, many additional details list hashtags hyperlinks contained tweet. introduce tidytags package approach allows simple data collection TAGS rigorous data analysis R statistical computing environment. short, tidytags first uses TAGS easily automatically collect tweet ID numbers provides wrapper rtweet R package [@kearney2019] re-query Twitter API collect additional metadata. tidytags offers several functions clean data perform additional calculations geolocation social network analysis.","code":""},{"path":"https://docs.ropensci.org/tidytags/paper.html","id":"getting-started-with-tidytags","dir":"","previous_headings":"","what":"Getting started with tidytags","title":"Summary","text":"help initial tidytags setup, see Getting started tidytags guide tidytags website. Specifically, guide offers help four key tasks: Making sure TAGS tweet collector can accessed Getting storing Google API key Getting storing Twitter API tokens Getting storing OpenCage Geocoding API key (optional; required geocoding) walkthrough numerous additional tidytags functions, see Using tidytags conference hashtag guide.","code":""},{"path":"https://docs.ropensci.org/tidytags/paper.html","id":"the-tidytags-workflow","dir":"","previous_headings":"","what":"The tidytags Workflow","title":"Summary","text":"workflow Twitter research formalized tidytags. workflow simple enough beginning programmers get started powerful enough serve analytic foundation research featured academic journals Computers & Education [@greenhalgh_et_al2020], Journal Research Technology Education [@staudtwillet2019], TechTrends [@greenhalgh_et_al2018]. tidytags workflow exploring Twitter data time using R includes: Set Twitter Archiving Google Sheet TAGS tweet collector [@hawksey2016] . View tweets collected TAGS using function get_tags() either TAGS tweet collector URL Google Sheet identifier (.e., alphanumeric string following “https://docs.google.com/spreadsheets/d/” TAGS tweet collector’s URL). Pull additional tweet metadata using function pull_tweet_data(). Calculate additional tweet attributes using function process_tweets(). Analyze hyperlinks web domains tweets using function get_url_domain(). Geocode tweeter locations creating map visualizations using function geocode_tags(). Analyze social network tweeters using function create_edgelist(). Append additional tweeter information edgelist using function add_users_data(). , data shaped straightforward use igraph R package [@csardi_nepusz2006] tidygraph R package [@pedersen2020] social network analysis ggraph R package [@pedersen2021] network visualization.","code":"aect_tweets_tags <- read_tags(\"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\") aect_tweets_full <- pull_tweet_data(aect_tweets_tags) aect_tweets_processed <- process_tweets(aect_tweets_full) tweet_urls <- purrr::flatten_chr(aect_tweets_processed$urls_url) tweet_urls <- tweet_urls[!is.na(tweet_urls)]  # Remove NA values tweet_domains <- get_url_domain(tweet_urls) aect_places <- dplyr::distinct(aect_tweets_processed, location, .keep_all = TRUE) aect_geo_coords <- geocode_tags(aect_places)  if (requireNamespace(\"mapview\", quietly = TRUE)) {   mapview::mapview(aect_geo_coords) } aect_edgelist <- create_edgelist(aect_tweets_processed) aect_senders_receivers_data <- add_users_data(aect_edgelist)"},{"path":"https://docs.ropensci.org/tidytags/paper.html","id":"conclusion","dir":"","previous_headings":"","what":"Conclusion","title":"Summary","text":"tidytags intended lower barriers powerful analyses Twitter data. combining easy--use Twitter Archiving Google Sheet TAGS [@hawksey2016] collect large volume longitudinal data Twitter, analysis rtweet R package [@kearney2019], new functions facilitate extend combined use, tidytags potential assist collection Tweets wide range social-science-related analyses research.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/tidytags/reference/add_users_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve user information for everyone in an edgelist — add_users_data","title":"Retrieve user information for everyone in an edgelist — add_users_data","text":"Updates edgelist created create_edgelist() appending user data retrieved lookup_many_users(). resulting dataframe adds many additional columns appends \"_sender\" \"_receiver\" column names.","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/add_users_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve user information for everyone in an edgelist — add_users_data","text":"","code":"add_users_data(edgelist)"},{"path":"https://docs.ropensci.org/tidytags/reference/add_users_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve user information for everyone in an edgelist — add_users_data","text":"edgelist edgelist senders receivers, returned function create_edgelist().","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/add_users_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve user information for everyone in an edgelist — add_users_data","text":"dataframe form edgelist (.e., senders receivers) well numerous, appropriately named columns details senders receivers.","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/add_users_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve user information for everyone in an edgelist — add_users_data","text":"function requires authentication; please see vignette(\"setup\", package = \"tidytags\")","code":""},{"path":[]},{"path":"https://docs.ropensci.org/tidytags/reference/add_users_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve user information for everyone in an edgelist — add_users_data","text":"","code":"if (FALSE) {  example_url <- \"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\" tmp_df <- pull_tweet_data(read_tags(example_url)) add_users_data(create_edgelist(tmp_df)) }"},{"path":"https://docs.ropensci.org/tidytags/reference/create_edgelist.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an edgelist where senders and receivers are defined by different types\nof Twitter interactions — create_edgelist","title":"Create an edgelist where senders and receivers are defined by different types\nof Twitter interactions — create_edgelist","text":"Starting dataframe Twitter data imported R read_tags() additional metadata retrieved pull_tweet_data(), create_edgelist() processes statuses calling process_tweets() removes statuses requested type (e.g., replies, retweets, quote tweets, mentions) calling filter_by_tweet_type(). Finally, create_edgelist() pulls senders receivers specified type statuses, adds new column called edge_type.","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/create_edgelist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an edgelist where senders and receivers are defined by different types\nof Twitter interactions — create_edgelist","text":"","code":"create_edgelist(df, type = \"all\")"},{"path":"https://docs.ropensci.org/tidytags/reference/create_edgelist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an edgelist where senders and receivers are defined by different types\nof Twitter interactions — create_edgelist","text":"df dataframe returned pull_tweet_data() type specific kind statuses used define interactions around edgelist built. Choices include \"reply\", \"retweet\", \"quote\", \"mention.\" Defaults \".\"","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/create_edgelist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an edgelist where senders and receivers are defined by different types\nof Twitter interactions — create_edgelist","text":"dataframe edgelist defined interactions type statuses specified. dataframe three columns: sender, receiver, edge_type.","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/create_edgelist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an edgelist where senders and receivers are defined by different types\nof Twitter interactions — create_edgelist","text":"","code":"if (FALSE) {  example_url <- \"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\" tmp_df <- pull_tweet_data(read_tags(example_url))  full_edgelist <- create_edgelist(tmp_df) full_edgelist  reply_edgelist <- create_edgelist(tmp_df, type = \"reply\") retweet_edgelist <- create_edgelist(tmp_df, type = \"retweet\") quote_edgelist <- create_edgelist(tmp_df, type = \"quote\") mention_edgelist <- create_edgelist(tmp_df, type = \"mention\") }"},{"path":"https://docs.ropensci.org/tidytags/reference/filter_by_tweet_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter a Twitter dataset to only include statuses of a particular type — filter_by_tweet_type","title":"Filter a Twitter dataset to only include statuses of a particular type — filter_by_tweet_type","text":"Starting dataframe Twitter data imported R read_tags() additional metadata retrieved pull_tweet_data(), filter_by_tweet_type() processes statuses calling process_tweets() removes statuses requested type (e.g., replies, retweets, quote tweets, mentions). filter_by_tweet_type() useful function , also used create_edgelist().","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/filter_by_tweet_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter a Twitter dataset to only include statuses of a particular type — filter_by_tweet_type","text":"","code":"filter_by_tweet_type(df, type)"},{"path":"https://docs.ropensci.org/tidytags/reference/filter_by_tweet_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter a Twitter dataset to only include statuses of a particular type — filter_by_tweet_type","text":"df dataframe returned pull_tweet_data() type specific kind statuses kept dataset filtering rest. Choices typeinclude \"reply\", \"retweet\", \"quote\", \"mention.\"","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/filter_by_tweet_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter a Twitter dataset to only include statuses of a particular type — filter_by_tweet_type","text":"dataframe processed statuses fewer rows input dataframe. statuses specified type remain.","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/filter_by_tweet_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter a Twitter dataset to only include statuses of a particular type — filter_by_tweet_type","text":"","code":"if (FALSE) {  example_url <- \"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\" tmp_df <- pull_tweet_data(read_tags(example_url))  only_replies <- filter_by_tweet_type(tmp_df, \"reply\") only_retweets <- filter_by_tweet_type(tmp_df, \"retweet\") only_quote_tweets <- filter_by_tweet_type(tmp_df, \"quote\") only_mentions <- filter_by_tweet_type(tmp_df, \"mention\") }"},{"path":"https://docs.ropensci.org/tidytags/reference/geocode_tags.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve geographic coordinates — geocode_tags","title":"Retrieve geographic coordinates — geocode_tags","text":"geocode_tags() retrieves geographic coordinates (.e., latitude longitude) based locations listed Twitter user profiles. geocode_tags() pulls OpenCage Geocoding API, requires OpenCage Geocoding API Key. can easily secure key OpenCage; read . recommend saving OpenCage Geocoding API Key .Renviron file OPENCAGE_KEY. can quickly access file using R code usethis::edit_r_environ(scope='user'). Add line file reads: OPENCAGE_KEY=\"PasteYourOpenCageKeyInsideTheseQuotes\". read key R, use code Sys.getenv('OPENCAGE_KEY'). Note geocode_tags() function retrieves saved API key automatically securely. saved .Renviron file, quit R session restart. function geocode_tags() work now .","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/geocode_tags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve geographic coordinates — geocode_tags","text":"","code":"geocode_tags(df)"},{"path":"https://docs.ropensci.org/tidytags/reference/geocode_tags.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve geographic coordinates — geocode_tags","text":"df dataframe tibble","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/geocode_tags.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve geographic coordinates — geocode_tags","text":"tibble geographic coordinates (.e., latitude longitude) can used plot locations map","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/geocode_tags.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve geographic coordinates — geocode_tags","text":"function requires authentication; please see vignette(\"setup\", package = \"tidytags\")","code":""},{"path":[]},{"path":"https://docs.ropensci.org/tidytags/reference/geocode_tags.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve geographic coordinates — geocode_tags","text":"","code":"if (FALSE) {  example_url <- \"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\" tmp_df <- pull_tweet_data(read_tags(example_url), n = 10) tmp_geo_coords <- geocode_tags(tmp_df) tmp_geo_coords  if (requireNamespace(\"sf\", quietly = TRUE)) {   locations <- sf::st_as_sf(     tmp_geo_coords,     coords = c(x = \"longitude\", y = \"latitude\"),     crs = 4326   ) }  if (requireNamespace(\"mapview\", quietly = TRUE)) {   mapview::mapview(locations) }  }"},{"path":"https://docs.ropensci.org/tidytags/reference/get_char_tweet_ids.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Twitter status ID numbers as character strings — get_char_tweet_ids","title":"Get Twitter status ID numbers as character strings — get_char_tweet_ids","text":"function useful Google Sheets (hence TAGS) typically round large numbers exponential form. Thus, status ID numbers large, often get corrupted rounding process. reliable way get full status ID numbers using function, get_char_tweet_ids(), pull ID numbers URL linking specific statuses.","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/get_char_tweet_ids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Twitter status ID numbers as character strings — get_char_tweet_ids","text":"","code":"get_char_tweet_ids(x)"},{"path":"https://docs.ropensci.org/tidytags/reference/get_char_tweet_ids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Twitter status ID numbers as character strings — get_char_tweet_ids","text":"x dataframe containing column name 'status_url' (.e., hyperlink specific statuses), returned read_tags(), vector status URLs, contained 'status_url' column dataframe returned tidytags::read_tags()","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/get_char_tweet_ids.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Twitter status ID numbers as character strings — get_char_tweet_ids","text":"vector Twitter status IDs character strings","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/get_char_tweet_ids.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Twitter status ID numbers as character strings — get_char_tweet_ids","text":"","code":"if (FALSE) { example_url <- \"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\" tags_content <- read_tags(example_url) get_char_tweet_ids(tags_content[1:10, ]) get_char_tweet_ids(tags_content$status_url[1:10]) get_char_tweet_ids(   \"https://twitter.com/tweet__example/status/1176592704647716864\") }"},{"path":"https://docs.ropensci.org/tidytags/reference/get_upstream_tweets.html","id":null,"dir":"Reference","previous_headings":"","what":"Collect upstream statuses and add to dataset — get_upstream_tweets","title":"Collect upstream statuses and add to dataset — get_upstream_tweets","text":"Twitter API offers reply_to_status_id column, possible iteratively reconstruct reply threads upstream direction, , retrieving statuses composed earlier replies dataset. get_upstream_tweets() function collects upstream replies previously found dataset. Keep mind way predict far upstream can trace back reply thread, running get_upstream_tweets() take potentially hit Twitter API rate limit 90,000 statuses 15-minute period.","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/get_upstream_tweets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collect upstream statuses and add to dataset — get_upstream_tweets","text":"","code":"get_upstream_tweets(df)"},{"path":"https://docs.ropensci.org/tidytags/reference/get_upstream_tweets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collect upstream statuses and add to dataset — get_upstream_tweets","text":"df dataframe statuses full metadata Twitter API returned pull_tweet_data()","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/get_upstream_tweets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collect upstream statuses and add to dataset — get_upstream_tweets","text":"new, expanded dataframe includes retrievable upstream replies","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/get_upstream_tweets.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Collect upstream statuses and add to dataset — get_upstream_tweets","text":"function requires authentication; please see vignette(\"setup\", package = \"tidytags\")","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/get_upstream_tweets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Collect upstream statuses and add to dataset — get_upstream_tweets","text":"","code":"if (FALSE) { example_url <- \"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\" tmp_df <- pull_tweet_data(read_tags(example_url)) more_replies_df <- get_upstream_tweets(tmp_df) more_replies_df }"},{"path":"https://docs.ropensci.org/tidytags/reference/get_url_domain.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the domain name of URLs, even shortened URLs — get_url_domain","title":"Find the domain name of URLs, even shortened URLs — get_url_domain","text":"get_url_domain() retrieves Web domain name URL, including URLs shortened services bit.ly t.co","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/get_url_domain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the domain name of URLs, even shortened URLs — get_url_domain","text":"","code":"get_url_domain(x, wait = 10)"},{"path":"https://docs.ropensci.org/tidytags/reference/get_url_domain.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the domain name of URLs, even shortened URLs — get_url_domain","text":"x list vector hyperlinks, whether shortened expanded wait long (seconds) wait longurl::expand_urls() function retrieve full, expanded URL shortened URL (e.g., bit.ly). longurl default 2 seconds, found misses number valid URLs. , made default wait = 10 seconds, user can adjust like.","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/get_url_domain.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the domain name of URLs, even shortened URLs — get_url_domain","text":"list vector Web domain names","code":""},{"path":[]},{"path":"https://docs.ropensci.org/tidytags/reference/get_url_domain.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find the domain name of URLs, even shortened URLs — get_url_domain","text":"","code":"if (FALSE) {  get_url_domain(\"https://www.tidyverse.org/packages/\") get_url_domain(\"https://dplyr.tidyverse.org/\") get_url_domain(\"http://bit.ly/2SfWO3K\") }"},{"path":"https://docs.ropensci.org/tidytags/reference/lookup_many_tweets.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the fullest extent of metadata for more than 90,000 statuses — lookup_many_tweets","title":"Retrieve the fullest extent of metadata for more than 90,000 statuses — lookup_many_tweets","text":"function calls pull_tweet_data(), built-delay 15 minutes allow Twitter API reset looking 90,000 statuses","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/lookup_many_tweets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the fullest extent of metadata for more than 90,000 statuses — lookup_many_tweets","text":"","code":"lookup_many_tweets(x, alarm = FALSE)"},{"path":"https://docs.ropensci.org/tidytags/reference/lookup_many_tweets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the fullest extent of metadata for more than 90,000 statuses — lookup_many_tweets","text":"x list vector status ID numbers alarm audible notification batch 90,000 statuses completed","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/lookup_many_tweets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the fullest extent of metadata for more than 90,000 statuses — lookup_many_tweets","text":"dataframe statuses full metadata Twitter API","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/lookup_many_tweets.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve the fullest extent of metadata for more than 90,000 statuses — lookup_many_tweets","text":"function requires authentication; please see vignette(\"setup\", package = \"tidytags\")","code":""},{"path":[]},{"path":"https://docs.ropensci.org/tidytags/reference/lookup_many_tweets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve the fullest extent of metadata for more than 90,000 statuses — lookup_many_tweets","text":"","code":"if (FALSE) {  example_url <- \"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\" tags_content <- read_tags(example_url) lookup_many_tweets(tags_content$id_str) lookup_many_tweets(\"1176592704647716864\") lookup_many_tweets(\"1176592704647716864\", alarm = TRUE) }"},{"path":"https://docs.ropensci.org/tidytags/reference/lookup_many_users.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the fullest extent of tweet metadata for more than 90,000 users — lookup_many_users","title":"Retrieve the fullest extent of tweet metadata for more than 90,000 users — lookup_many_users","text":"function calls rtweet::lookup_users(), built-delay 15 minutes allow Twitter API reset looking 90,000 users.","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/lookup_many_users.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the fullest extent of tweet metadata for more than 90,000 users — lookup_many_users","text":"","code":"lookup_many_users(x, alarm = FALSE)"},{"path":"https://docs.ropensci.org/tidytags/reference/lookup_many_users.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the fullest extent of tweet metadata for more than 90,000 users — lookup_many_users","text":"x list vector user ID numbers alarm audible notification batch 90,000 users completed","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/lookup_many_users.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the fullest extent of tweet metadata for more than 90,000 users — lookup_many_users","text":"dataframe tweets full user metadata Twitter API","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/lookup_many_users.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve the fullest extent of tweet metadata for more than 90,000 users — lookup_many_users","text":"function requires authentication; please see vignette(\"setup\", package = \"tidytags\")","code":""},{"path":[]},{"path":"https://docs.ropensci.org/tidytags/reference/lookup_many_users.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve the fullest extent of tweet metadata for more than 90,000 users — lookup_many_users","text":"","code":"if (FALSE) {  example_url <- \"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\" tmp_df <- pull_tweet_data(read_tags(example_url)) users <- lookup_many_users(tmp_df$screen_name, alarm = TRUE) users  lookup_many_users(\"AECT\") lookup_many_tweets(\"12030342\", alarm = TRUE) }"},{"path":"https://docs.ropensci.org/tidytags/reference/process_tweets.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate additional information using status metadata — process_tweets","title":"Calculate additional information using status metadata — process_tweets","text":"Calculate additional information using status metadata","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/process_tweets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate additional information using status metadata — process_tweets","text":"","code":"process_tweets(df)"},{"path":"https://docs.ropensci.org/tidytags/reference/process_tweets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate additional information using status metadata — process_tweets","text":"df dataframe statuses full metadata Twitter API returned pull_tweet_data()","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/process_tweets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate additional information using status metadata — process_tweets","text":"dataframe several additional columns: word_count, character_count, mentions_count, hashtags_count_api, hashtags_count_regex, has_hashtags, urls_count_api, urls_count_regex, is_reply, is_self_reply","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/process_tweets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate additional information using status metadata — process_tweets","text":"","code":"if (FALSE) {  example_url <- \"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\" tmp_df <- pull_tweet_data(read_tags(example_url)) tmp_processed <- process_tweets(tmp_df) tmp_processed }"},{"path":"https://docs.ropensci.org/tidytags/reference/pull_tweet_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the fullest extent of status metadata available from the Twitter API — pull_tweet_data","title":"Retrieve the fullest extent of status metadata available from the Twitter API — pull_tweet_data","text":"TAGS archive imported R, pull_tweet_data() uses rtweet package query Twitter API. Using rtweet requires Twitter API keys associated approved developer account. Fortunately, rtweet vignette, Authentication, provides thorough guide obtaining Twitter API keys. Following directions, run rtweet::create_token() function, saves Twitter API keys .Renviron file. can also edit file directly using usethis::edit_r_environ(scope='user') function.","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/pull_tweet_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the fullest extent of status metadata available from the Twitter API — pull_tweet_data","text":"","code":"pull_tweet_data(df, url_vector = NULL, id_vector = NULL, n = NULL)"},{"path":"https://docs.ropensci.org/tidytags/reference/pull_tweet_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the fullest extent of status metadata available from the Twitter API — pull_tweet_data","text":"df dataframe containing column name 'status_url' (.e., hyperlink specific statuses), returned read_tags() url_vector vector status URLs, contained 'status_url' column dataframe returned tidytags::read_tags() id_vector vector statuses (.e., ID numbers, contained 'id_str' column dataframe returned tidytags::read_tags() n number statuses look , default total number tweet ID numbers available, capped 90,000 due Twitter API limitations.","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/pull_tweet_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the fullest extent of status metadata available from the Twitter API — pull_tweet_data","text":"dataframe statuses full metadata Twitter API","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/pull_tweet_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve the fullest extent of status metadata available from the Twitter API — pull_tweet_data","text":"function requires authentication; please see vignette(\"setup\", package = \"tidytags\")","code":""},{"path":[]},{"path":"https://docs.ropensci.org/tidytags/reference/pull_tweet_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve the fullest extent of status metadata available from the Twitter API — pull_tweet_data","text":"","code":"if (FALSE) {  ## Import data from a TAGS tracker: example_tags_tracker <- \"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\" tags_content <- read_tags(example_tags_tracker)  ## Use any of three input parameters (TAGS dataframe, `status_url` ##   column, or `id_str` column) pull_tweet_data(tags_content) pull_tweet_data(url_vector = tags_content$status_url) pull_tweet_data(id_vector = tags_content$id_str)  ## Specifying the parameter `n` clarifies how many statuses to look up, ##   but the returned values may be less than `n` because some statuses ##   may have been deleted or made protected since the TAGS tracker ##   originally recorded them. pull_tweet_data(tags_content, n = 10)  ## Note that the following two examples will return the same thing: pull_tweet_data(url_vector =   \"https://twitter.com/tweet__example/status/1176592704647716864\") pull_tweet_data(id_vector = \"1176592704647716864\") }"},{"path":"https://docs.ropensci.org/tidytags/reference/read_tags.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve a TAGS archive of Twitter statuses and bring into R — read_tags","title":"Retrieve a TAGS archive of Twitter statuses and bring into R — read_tags","text":"Keep mind read_tags() uses googlesheets4 package, one requirement TAGS tracker \"published web.\" , TAGS page open web browser, navigate File >> Publish web. Link field 'Entire document' Embed field 'Web page.' everything looks right, click Publish button. Next, click Share button top right corner Google Sheets browser window, select Get shareable link, set permissions 'Anyone link can view.'","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/read_tags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve a TAGS archive of Twitter statuses and bring into R — read_tags","text":"","code":"read_tags(tags_id, google_key = Sys.getenv(\"GOOGLE_API_KEY\"))"},{"path":"https://docs.ropensci.org/tidytags/reference/read_tags.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve a TAGS archive of Twitter statuses and bring into R — read_tags","text":"tags_id Google Sheet identifier (.e., alphanumeric string following \"https://docs.google.com/spreadsheets/d/\" TAGS tracker's URL.) google_key Google API key accessing Google Sheets.","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/read_tags.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve a TAGS archive of Twitter statuses and bring into R — read_tags","text":"tibble TAGS archive Twitter statuses","code":""},{"path":"https://docs.ropensci.org/tidytags/reference/read_tags.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve a TAGS archive of Twitter statuses and bring into R — read_tags","text":"function requires authentication; please see vignette(\"setup\", package = \"tidytags\")","code":""},{"path":[]},{"path":"https://docs.ropensci.org/tidytags/reference/read_tags.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve a TAGS archive of Twitter statuses and bring into R — read_tags","text":"","code":"if (FALSE) {  example_tags <- \"18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8\" read_tags(example_tags) }"},{"path":[]},{"path":"https://docs.ropensci.org/tidytags/news/index.html","id":"new-features-0-3-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"tidytags 0.3.0 (2022-02-04)","text":"Released tidytags CRAN first time. ### BUG FIXES Updated recent versions CI tests R-CMD-check test coverage. ### DOCUMENTATION FIXES Updated paper.md paper.bib coincide submission peer review Journal Open Source Software (JOSS).","code":""},{"path":[]},{"path":"https://docs.ropensci.org/tidytags/news/index.html","id":"new-features-0-2-1","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"tidytags 0.2.1 (2021-12-14)","text":"Added new function filter_by_tweet_type() filter Twitter dataset include statuses particular type (e.g., replies, retweets, quote tweets, mentions). Updated function create_edgelist() take “type” argument (e.g., “reply”, “retweet”, “quote”, “mention”, “”). replaces need specialized functions like create_mentions_edgelist().","code":""},{"path":[]},{"path":"https://docs.ropensci.org/tidytags/news/index.html","id":"new-features-0-2-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"tidytags 0.2.0 (2021-11-19)","text":"Added new function lookup_many_users() automatically iterate Twitter API limit pulling metadata 90,000 users one time ### BUG FIXES Updated several function names mask newer functions imported {rtweet}, example, get_mentions() now create_mentions_edgelist(), similar updates made function building edgelists quotes, replies, retweets Updated tests work latest version {vcr} Made fixes CI tests work real requests addition pre-recorded {vcr} data ### DOCUMENTATION FIXES Extensively updated README doc Setup vignette help scaffold {tidytags} setup","code":""},{"path":[]},{"path":"https://docs.ropensci.org/tidytags/news/index.html","id":"bug-fixes-0-1-2","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"tidytags 0.1.2 (2021-03-02)","text":"CI tests now work real requests addition pre-recorded vcr data Added Google API key accessing Google Sheet read_tags() ### DOCUMENTATION FIXES Clarified process obtaining setting API keys tokens Google, Twitter, OpenCage","code":""},{"path":[]},{"path":"https://docs.ropensci.org/tidytags/news/index.html","id":"new-features-0-1-1","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"tidytags 0.1.1 (2020-11-24)","text":"Switched OpenCage geocoding (previously used Google Maps API) Switched GitHub Actions (Travis CI) CI testing","code":""},{"path":"https://docs.ropensci.org/tidytags/news/index.html","id":"tidytags-010-2020-02-21","dir":"Changelog","previous_headings":"","what":"tidytags 0.1.0 (2020-02-21)","title":"tidytags 0.1.0 (2020-02-21)","text":"Initial release GitHub.","code":""}]
